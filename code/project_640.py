# -*- coding: utf-8 -*-
"""project_main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Gd52KvETe_vD9878g3USJUD26PCbFzC

## Install MMDetection
"""

from google.colab import drive
drive.mount('/content/drive')

# Check nvcc version
!nvcc -V
# Check GCC version
!gcc --version

# Commented out IPython magic to ensure Python compatibility.
# install dependencies: (use cu111 because colab has CUDA 11.1)
!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html

# install mmcv-full thus we could use CUDA operators
!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html

# Install mmdetection
!rm -rf mmdetection
!git clone https://github.com/open-mmlab/mmdetection.git
# %cd mmdetection

!pip install -e .

"""# **Setting up Environment**"""

from mmcv import collect_env
collect_env()

# Check Pytorch installation
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())

# Check MMDetection installation
import mmdet
print(mmdet.__version__)

# Check mmcv installation
from mmcv.ops import get_compiling_cuda_version, get_compiler_version
print(get_compiling_cuda_version())
print(get_compiler_version())

# We download the pre-trained checkpoints for inference and finetuning.
!mkdir checkpoints
!wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \
      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth

import mmcv
from mmcv.runner import load_checkpoint

from mmdet.apis import inference_detector, show_result_pyplot
from mmdet.models import build_detector

# Choose to use a config and initialize the detector
config = 'configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py'
# Setup a checkpoint file to load
checkpoint = '/content/drive/MyDrive/checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth'

# Set the device to be used for evaluation
device='cuda:0'

# Load the config
config = mmcv.Config.fromfile(config)
# Set pretrained to be None since we do not need pretrained model here
config.model.pretrained = None

# Initialize the detector
model = build_detector(config.model)

# Load checkpoint
checkpoint = load_checkpoint(model, checkpoint, map_location=device)

# Set the classes of models for inference
model.CLASSES = checkpoint['meta']['CLASSES']

# We need to set the model's cfg for inference
model.cfg = config

# Convert the model to GPU
model.to(device)
# Convert the model into evaluation mode
model.eval()

# Use the detector to do inference
img = 'demo/demo.jpg'
result = inference_detector(model, img)

# Let's plot the result
show_result_pyplot(model, img, result, score_thr=0.3)

# Let's take a look at the dataset image
import mmcv
import matplotlib.pyplot as plt

img = mmcv.imread('/content/drive/MyDrive/640_project/project_train/images/00001.jpg')
plt.figure(figsize=(15, 10))
plt.imshow(mmcv.bgr2rgb(img))
plt.show()

### Creating Datasetclass for our Bird detection dataset.
import os.path as osp
from pycocotools.coco import COCO
from mmdet.datasets.builder import DATASETS
from mmdet.datasets.custom import CustomDataset
import numpy as np

@DATASETS.register_module()
class BirdDetectionDataset(CustomDataset):
    CLASSES = ('bird',)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}
        self.img_infos = self.load_annotations(self.ann_file)

    def load_annotations(self, ann_file):
        self.coco = COCO(ann_file)
        self.cat_ids = self.coco.getCatIds(catNms=self.CLASSES)
        self.img_ids = self.coco.getImgIds(catIds=self.cat_ids)
        img_infos = []
        for i in self.img_ids:
            info = self.coco.loadImgs([i])[0]
            info['filename'] = osp.join(self.img_prefix, info['file_name'])
            img_infos.append(info)
        print(f'Loaded {len(img_infos)} images')
        return img_infos

    def get_ann_info(self, idx):
        img_id = self.img_infos[idx]['id']
        ann_ids = self.coco.getAnnIds(imgIds=[img_id])
        ann_info = self.coco.loadAnns(ann_ids)
        return self.parse_ann_info(self.img_infos[idx], ann_info)

    def parse_ann_info(self, img_info, ann_info):
        gt_bboxes = []
        gt_labels = []
        gt_bboxes_ignore = []
        gt_masks_ann = []

        for i, ann in enumerate(ann_info):
            if ann.get('ignore', False):
                continue
            x1, y1, w, h = ann['bbox']
            inter_w = max(0, min(x1 + w, img_info['width']) - max(x1, 0))
            inter_h = max(0, min(y1 + h, img_info['height']) - max(y1, 0))
            if inter_w * inter_h == 0:
                continue

            bbox = [x1, y1, x1 + w, y1 + h]

            if ann['iscrowd']:
                gt_bboxes_ignore.append(bbox)
            else:
                gt_bboxes.append(bbox)
                gt_labels.append(self.cat2label[ann['category_id']])
                gt_masks_ann.append(ann['segmentation'])

        if gt_bboxes:
            gt_bboxes = np.array(gt_bboxes, dtype=np.float32)
            gt_labels = np.array(gt_labels, dtype=np.int64)
        else:
            gt_bboxes = np.zeros((0, 4), dtype=np.float32)
            gt_labels = np.array([], dtype=np.int64)

        if gt_bboxes_ignore:
            gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)
        else:
            gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)

        seg_map = img_info['filename'].replace('jpg', 'png')

        ann = dict(
            bboxes=gt_bboxes,
            labels=gt_labels,
            bboxes_ignore=gt_bboxes_ignore,
            masks=gt_masks_ann,
            seg_map=seg_map)

        return ann

## Setting the configuration
from mmcv import Config
cfg = Config.fromfile('/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_bird.py')

from mmdet.apis import set_random_seed

# Modify dataset type and path
cfg.dataset_type = 'BirdDetectionDataset'
cfg.data_root = '/content/drive/MyDrive/640_project/project_train/'

cfg.data.test.type = 'BirdDetectionDataset'
cfg.data.test.data_root = '/content/drive/MyDrive/640_project/project_train/'
cfg.data.test.ann_file = 'annotations/merged_train.json'
cfg.data.test.img_prefix = 'images'

cfg.data.train.type = 'BirdDetectionDataset'
cfg.data.train.data_root = '/content/drive/MyDrive/640_project/project_train/'
cfg.data.train.ann_file = '/content/drive/MyDrive/640_project/project_train/annotations/split_train_coco.json'
cfg.data.train.img_prefix = 'images'

# You should also have a separate validation dataset
cfg.data.val.type = 'BirdDetectionDataset'
cfg.data.val.data_root = '/content/drive/MyDrive/640_project/project_train/'
cfg.data.val.ann_file = '/content/drive/MyDrive/640_project/project_train/annotations/split_val_coco.json'  # Assuming you have a validation annotation file
cfg.data.val.img_prefix = 'images'

# modify num classes of the model in box head
cfg.model.roi_head.bbox_head.num_classes = 1  # Only one class: bird
cfg.load_from = '/content/drive/MyDrive/checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth' 

# Set up working dir to save files and logs.
cfg.work_dir = './tutorial_exps'
cfg.runner.max_epochs = 2
# The original learning rate (LR) is set for 8-GPU training.
# We divide it by 8 since we only use one GPU.
cfg.optimizer.lr = 0.02 / 8
cfg.lr_config.warmup = None
cfg.log_config.interval = 50

# Change the evaluation metric since we use customized dataset.
cfg.evaluation.metric = 'mAP'
# We can set the evaluation interval to reduce the evaluation times
cfg.evaluation.interval = 12
# We can set the checkpoint saving interval to reduce the storage cost
cfg.checkpoint_config.interval = 12

# Set seed thus the results are more reproducible
cfg.seed = 0
set_random_seed(0, deterministic=False)
cfg.device = 'cuda'
cfg.gpu_ids = range(1)

# We can also use tensorboard to log the training process
cfg.log_config.hooks = [
    dict(type='TextLoggerHook'),
    dict(type='TensorboardLoggerHook')]

# We can initialize the logger for training and have a look
# at the final config used for training
print(f'Config:\n{cfg.pretty_text}')

from mmdet.datasets import build_dataset
from mmdet.models import build_detector
from mmdet.apis import train_detector


# Build dataset
datasets = [build_dataset(cfg.data.train)]

# Build the detector
model = build_detector(cfg.model)
# Add an attribute for visualization convenience
model.CLASSES = datasets[0].CLASSES

# Create work_dir
mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
train_detector(model, datasets, cfg, distributed=False, validate=True)

# Commented out IPython magic to ensure Python compatibility.
# load tensorboard in colab
# %load_ext tensorboard

# see curves in tensorboard
# %tensorboard --logdir ./tutorial_exps

import os
import json
import mmcv
from mmdet.apis import init_detector, inference_detector

def run_model_on_test_data(model, test_img_dir, output_json_path):
    results = []

    for image_name in os.listdir(test_img_dir):
        image_path = os.path.join(test_img_dir, image_name)
        image_id = int(os.path.splitext(image_name)[0])  # Assuming image_name is like "123.jpg"

        result = inference_detector(model, image_path)
        for category_id, bboxes in enumerate(result):
            for bbox in bboxes:
                x1, y1, x2, y2, score = bbox
                width = x2 - x1
                height = y2 - y1

                detection = {
                    "image_id": image_id,
                    "bbox": [float(x1), float(y1), float(width), float(height)],
                    "score": float(score),
                    "category_id": category_id,
                }
                results.append(detection)

    with open(output_json_path, "w") as f:
        json.dump(results, f)

# Load the trained model
config_file = './configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py'
checkpoint_file = '/content/mmdetection/tutorial_exps/epoch_2.pth'

# Build the model from the config and load the checkpoint
model = init_detector(config_file, checkpoint_file, device='cuda:0')

# Run the model on test data and save the results in output.json
test_images_path = '/content/drive/MyDrive/640_project/project_test/images'
output_json_path = 'output.json'
run_model_on_test_data(model, test_images_path, output_json_path)